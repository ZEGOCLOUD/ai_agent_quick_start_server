import { NextResponse } from 'next/server';
import type { NextRequest } from 'next/server';
import { retrieveFromRagflow } from '@/lib/rag/ragflow';
import OpenAI from 'openai';
import type { ChatCompletionCreateParams } from 'openai/resources/chat';
import { retrieveFromBailian } from '@/lib/rag/bailian';


export async function POST(request: NextRequest) {
    // è®¤è¯æ£€æŸ¥
    const authHeader = request.headers.get('authorization');
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
        return NextResponse.json(
            { error: 'Unauthorized' },
            { status: 401 }
        );
    }

    try {
        const requestData: ChatCompletionCreateParams = await request.json();
        console.log("requestData", requestData);
        console.log("requestData", JSON.stringify(requestData));

        // è¯»å–APIå¯†é’¥ï¼Œå³åœ¨ä½¿ç”¨ä»¥ä¸‹æ–¹å¼è¯·æ±‚æ—¶å¸¦ä¸Šçš„ apiKey çš„å€¼ã€‚AIAgent æœåŠ¡ç«¯ä¹Ÿä½¿ç”¨ä»¥ä¸‹æ–¹å¼è¯·æ±‚ã€‚
        // const openai = new OpenAI({
        //     apiKey: "xxx",
        //     baseURL: "xxx"
        // });
        // æ‚¨åœ¨è¯»å–åˆ° apiKey åï¼Œå¯ä»¥åšå¿…è¦çš„ä¸šåŠ¡æ ¡éªŒã€‚å®ƒä¸ä¸€å®šæ˜¯ LLM çš„ apiKeyï¼Œå› ä¸ºæ˜¯é€ä¼ çš„ï¼Œæ‰€ä»¥ä½ å¯ä»¥ä¼ ä»»æ„å†…å®¹ã€‚
        const apiKey = authHeader.split(' ')[1];

        // æ£€æŸ¥å¿…éœ€å­—æ®µ
        if (!requestData.messages || requestData.messages.length === 0) {
            return NextResponse.json(
                { error: 'Messages are required' },
                { status: 400 }
            );
        }

        // æ£€æŸ¥æ˜¯å¦è¦æ±‚æµå¼å“åº”
        if (requestData.stream) {
            // è¯»å– Model
            // ç”±äºåœ¨æ³¨å†Œ AIAgent æˆ–è€…åˆ›å»º AIAgent å®ä¾‹æ—¶ï¼Œä¼šä¼ å…¥å›ºå®šçš„ Model æ‰€ä»¥ è¿™é‡Œå¯ä»¥ä¼ ä¸€ä¸ªæ™®é€šç»™ LLM çš„ Modelã€‚
            // åŒæ—¶ä½ ä¹Ÿå¯ä»¥é€šè¿‡è¿™ä¸ªå€¼ä¼ é€’ä¸€äº›é¢å¤–çš„ä¸šåŠ¡ä¿¡æ¯ã€‚æ¯”å¦‚ è¿™ä¸ª Model å®é™…æ˜¯ä¸šåŠ¡æ ‡å¿—ï¼Œæ ‡è¯†æ˜¯ç›´æ’­/è¯­èŠæˆ¿ç­‰ç­‰ã€‚
            const model = requestData.model;

            // è¯»å– SystemPrompt
            // ç”±äºåœ¨æ³¨å†Œ AIAgent æˆ–è€…åˆ›å»º AIAgent å®ä¾‹æ—¶ï¼Œä¼šä¼ å…¥å›ºå®šçš„ SystemPrompt æ‰€ä»¥ è¿™é‡Œå¯ä»¥ä¼ ä¸€ä¸ªæ™®é€šç»™ LLM çš„ SystemPromptã€‚
            // åŒæ—¶ä½ ä¹Ÿå¯ä»¥é€šè¿‡è¿™ä¸ªå€¼ä¼ é€’ä¸€äº›é¢å¤–çš„ä¸šåŠ¡ä¿¡æ¯ã€‚æ¯”å¦‚å¸¦ä¸Šç”¨æˆ·çš„ä¿¡æ¯ã€ç­‰çº§ã€åå¥½ç­‰ç­‰ã€‚ç„¶åä¾æ­¤å†è°ƒç”¨ LLM æ—¶é’ˆå¯¹æ€§çš„ä¿®æ”¹å®é™…ç»™ LLM çš„ SystemPromptã€‚
            const systemMessage = requestData.messages.find(message => message.role === 'system');

            // è¯»å–æœ€æ–°ä¸€æ¡ User Messageï¼ˆæœ€æ–°çš„åœ¨æ•°ç»„æœ€åï¼‰
            // AIAgent åœ¨å‘ä½ çš„æ¥å£å‘èµ·è¯·æ±‚æ—¶ï¼Œä¼šå¸¦ä¸Š Messages å‚æ•°ã€‚è¿™ä¸ªå‚æ•°ä¹ŸåŒ…æ‹¬ SystemPromptã€‚
            const latestUserMessage = [...requestData.messages].reverse().find(message => message.role === 'user');

            // è¯»å–å…¶ä»–ç¬¦åˆ OpenAI åè®®çš„ LLM å‚æ•°ç±»ä¼¼ï¼Œè¿™é‡Œä¸å†èµ˜è¿°ã€‚

            // åˆ›å»ºæµå¼å“åº”
            const stream = new TransformStream();
            const writer = stream.writable.getWriter();
            const encoder = new TextEncoder();
            try {
                let kbContent = "";
                // è°ƒç”¨çŸ¥è¯†åº“æŸ¥è¯¢æ¥å£ï¼Œè·å–çŸ¥è¯†åº“æŸ¥è¯¢ç»“æœ
                if (process.env.KB_TYPE === "ragflow") {
                    console.log("è°ƒç”¨ Ragflow çŸ¥è¯†åº“æŸ¥è¯¢æ¥å£");
                    const ragflowResponse = await retrieveFromRagflow({
                        question: latestUserMessage?.content as string,
                    });
                    kbContent = ragflowResponse.kbContent;
                } else if (process.env.KB_TYPE === "bailian") {
                    console.log("è°ƒç”¨ Bailian çŸ¥è¯†åº“æŸ¥è¯¢æ¥å£");
                    const bailianResponse = await retrieveFromBailian({ query: latestUserMessage?.content as string });
                    kbContent = bailianResponse.kbContent;
                }

                // å°†ç”¨æˆ·æœ€æ–°ä¸€æ¡ User Message å’ŒçŸ¥è¯†åº“æŸ¥è¯¢ç»“æœè¿›è¡Œåˆå¹¶ï¼Œåœ¨æ›¿æ¢ messages æ•°ç»„æœ€åä¸€ä¸ªå…ƒç´ ï¼Œç„¶åè°ƒç”¨ LLM è¿›è¡Œå›ç­”
                // å°æç¤ºğŸ””ï¼šéƒ¨åˆ†å‚å•†çš„æ¨¡å‹æ˜¯æä¾›ä¸Šä¸‹æ–‡ç¡¬ç›˜ç¼“å­˜çš„ï¼Œæ‰€ä»¥è®¡ç®—ä»·æ ¼æ—¶æœ‰ç¼“å­˜çš„è®¡ä»·ä¼šä¾¿å®œå¾ˆå¤šã€‚ä¿æŒ SystemPrompt ä¸å˜ï¼Œåªæ›¿æ¢ User Message å¯æœ‰æ•ˆæå‡ç¼“å­˜å‘½ä¸­æ¦‚ç‡ä»è€Œé™ä½æˆæœ¬å¹¶ä¸”ç¼©çŸ­æ¨ç†æ—¶é—´ã€‚
                requestData.messages[requestData.messages.length - 1] = {
                    role: 'user',
                    content: `${latestUserMessage?.content}\nä»¥ä¸‹æ˜¯çŸ¥è¯†åº“æŸ¥è¯¢ç»“æœ:\n${kbContent}`,
                };

                // è°ƒç”¨ LLM è¿›è¡Œå›ç­”ï¼ˆä½¿ç”¨ OpenAI çš„ SDKï¼‰
                const openai = new OpenAI({
                    apiKey: apiKey,
                    baseURL: process.env.LLM_BASE_URL_REAL
                });
                // å¤„ç†æµå¼å“åº”
                const completion = await openai.chat.completions.create({
                    model: model,
                    stream: true,
                    messages: requestData.messages
                });
                console.log("completion created successfully");
                for await (const chunk of completion) {
                    // æ³¨æ„âš ï¸ï¼šAIAgent è¦æ±‚æœ€åä¸€ä¸ªæœ‰æ•ˆæ•°æ®å¿…é¡»åŒ…å« "finish_reason":"stop"ä¸”æœ€åå¿…é¡»å‘é€ä¸€æ¡ç»“æŸæ•°æ®ï¼šdata: [DONE]ï¼Œå¦‚æœä¸å‘é€å¯èƒ½ä¼šå¯¼è‡´æ™ºèƒ½ä½“ä¸å›ç­”æˆ–è€…å›ç­”ä¸å®Œæ•´ã€‚
                    // æŸäº›æ¨¡å‹ä¸ä¼šåœ¨æµå¼å“åº”ä¸­è¿”å› finish_reasonï¼Œè¿™ç§æƒ…å†µéœ€è¦è‡ªå·±æ ¹æ®ä¿®æ”¹ä¸€ä¸‹chunkå†…å®¹å†ä¼ å›ç»™ AIAgentã€‚
                    const ssePart = `data: ${JSON.stringify(chunk)}\n`;
                    writer.write(encoder.encode(ssePart));
                }

            } catch (error) {
                console.error('Stream processing error:', error);
            } finally {
                // å‘é€ç»“æŸæ ‡è®°
                writer.write(encoder.encode('data: [DONE]\n\n'));
                writer.close();
                console.log("writer closed");
            }


            return new Response(stream.readable, {
                headers: {
                    'Content-Type': 'text/event-stream',
                    'Cache-Control': 'no-cache',
                    'Connection': 'keep-alive',
                    'Access-Control-Allow-Origin': '*',
                },
            });
        } else {
            // AIAgent ä¸æ”¯æŒéæµå¼å“åº”ï¼Œç›´æ¥è¿”å›é”™è¯¯ç 
            return NextResponse.json(
                { error: 'Streaming is required' },
                { status: 400 }
            );
        }
    } catch (error) {
        console.error('Error processing request:', error);
        return NextResponse.json(
            { error: 'Internal server error' },
            { status: 500 }
        );
    }
}

// æ·»åŠ OPTIONSæ–¹æ³•æ”¯æŒCORSé¢„æ£€
export async function OPTIONS() {
    return NextResponse.json({}, {
        headers: {
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Methods': 'POST, OPTIONS',
            'Access-Control-Allow-Headers': 'Content-Type, Authorization',
        },
    });
}